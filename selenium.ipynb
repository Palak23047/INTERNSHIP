{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00829af8",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location.\n",
    "You have to scrape the job-title, job-location, company_name, experience_required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "b3ef3a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\mohitlewis\\anaconda3\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\mohitlewis\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\mohitlewis\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\mohitlewis\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\mohitlewis\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\mohitlewis\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.0.0rc9)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\mohitlewis\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: outcome in c:\\users\\mohitlewis\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\mohitlewis\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\mohitlewis\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\mohitlewis\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\mohitlewis\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\mohitlewis\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\mohitlewis\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\mohitlewis\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\mohitlewis\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\mohitlewis\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "9fe91913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "4dd965eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\MohitLewis\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "727914f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "0da0efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "24355adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div[1]/div[5]/div/div/div/input\")\n",
    "location.send_keys('Banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "fdd39a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "0e6b1dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "Exp_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "d572118a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analytics and Interpretation Business Analyst',\n",
       " 'Data Analyst - CRM Platform',\n",
       " 'Data Analyst - FinTech',\n",
       " 'Data Analyst - FinTech',\n",
       " 'Data Analyst',\n",
       " 'Freelancer - Data Analyst - Contractual Role',\n",
       " 'Lead Data Analyst (SQL & Python) - US MNC (analytics)',\n",
       " 'data analyst / data analytics - US MNC (analytics)']"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping job title from given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "69767992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Mumbai, Hyderabad/Secunderabad, Pune, Chennai, Ahmedabad, Bangalore/Bengaluru',\n",
       " 'Kolkata, Mumbai, Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru',\n",
       " 'Kolkata, Mumbai, Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru\\n(WFH during Covid)',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru\\n(WFH during Covid)']"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping job location from given page\n",
    "location_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "85934838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Latentview',\n",
       " 'Varite',\n",
       " 'Accenture',\n",
       " 'Artech infosystem',\n",
       " 'Primo Hiring',\n",
       " 'Primo Hiring',\n",
       " 'What Digital Technologies Private Limited',\n",
       " 'WEN',\n",
       " 'Aspyra HR Services',\n",
       " 'Aspyra HR Services']"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "01ec2d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[...], [...], [...], [...], [...], [...], [...], [...], [...], [...]]"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping job experience from given page\n",
    "\n",
    "experience_tags=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience'] //span\")\n",
    "for i in experience_tags[0:10]:\n",
    "    Exp=i.text\n",
    "    Exp_required.append(Exp_required)\n",
    "Exp_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "36226993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(Exp_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "9d33659f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>Exp_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Latentview</td>\n",
       "      <td>[[[[[...], [...], [...], [...], [...], [...], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Varite</td>\n",
       "      <td>[[[[[...], [...], [...], [...], [...], [...], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analytics and Interpretation Business Ana...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>[[[[[...], [...], [...], [...], [...], [...], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - CRM Platform</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...</td>\n",
       "      <td>Artech infosystem</td>\n",
       "      <td>[[[[[...], [...], [...], [...], [...], [...], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>[[[[[...], [...], [...], [...], [...], [...], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>[[[[[...], [...], [...], [...], [...], [...], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>What Digital Technologies Private Limited</td>\n",
       "      <td>[[[[[...], [...], [...], [...], [...], [...], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Freelancer - Data Analyst - Contractual Role</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>WEN</td>\n",
       "      <td>[[[[[...], [...], [...], [...], [...], [...], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead Data Analyst (SQL &amp; Python) - US MNC (ana...</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru\\n(WFH du...</td>\n",
       "      <td>Aspyra HR Services</td>\n",
       "      <td>[[[[[...], [...], [...], [...], [...], [...], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data analyst / data analytics - US MNC (analyt...</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru\\n(WFH du...</td>\n",
       "      <td>Aspyra HR Services</td>\n",
       "      <td>[[[[[...], [...], [...], [...], [...], [...], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0                                Senior Data Analyst   \n",
       "1                                       Data Analyst   \n",
       "2  Data Analytics and Interpretation Business Ana...   \n",
       "3                        Data Analyst - CRM Platform   \n",
       "4                             Data Analyst - FinTech   \n",
       "5                             Data Analyst - FinTech   \n",
       "6                                       Data Analyst   \n",
       "7       Freelancer - Data Analyst - Contractual Role   \n",
       "8  Lead Data Analyst (SQL & Python) - US MNC (ana...   \n",
       "9  data analyst / data analytics - US MNC (analyt...   \n",
       "\n",
       "                                        job_location  \\\n",
       "0                       Chennai, Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3  Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...   \n",
       "4  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "5  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8  Gurgaon/Gurugram, Bangalore/Bengaluru\\n(WFH du...   \n",
       "9  Gurgaon/Gurugram, Bangalore/Bengaluru\\n(WFH du...   \n",
       "\n",
       "                                company_name  \\\n",
       "0                                 Latentview   \n",
       "1                                     Varite   \n",
       "2                                  Accenture   \n",
       "3                          Artech infosystem   \n",
       "4                               Primo Hiring   \n",
       "5                               Primo Hiring   \n",
       "6  What Digital Technologies Private Limited   \n",
       "7                                        WEN   \n",
       "8                         Aspyra HR Services   \n",
       "9                         Aspyra HR Services   \n",
       "\n",
       "                                        Exp_required  \n",
       "0  [[[[[...], [...], [...], [...], [...], [...], ...  \n",
       "1  [[[[[...], [...], [...], [...], [...], [...], ...  \n",
       "2  [[[[[...], [...], [...], [...], [...], [...], ...  \n",
       "3  [[[[[...], [...], [...], [...], [...], [...], ...  \n",
       "4  [[[[[...], [...], [...], [...], [...], [...], ...  \n",
       "5  [[[[[...], [...], [...], [...], [...], [...], ...  \n",
       "6  [[[[[...], [...], [...], [...], [...], [...], ...  \n",
       "7  [[[[[...], [...], [...], [...], [...], [...], ...  \n",
       "8  [[[[[...], [...], [...], [...], [...], [...], ...  \n",
       "9  [[[[[...], [...], [...], [...], [...], [...], ...  "
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe from above data\n",
    "df=pd.DataFrame({'job_title':job_title,'job_location':job_location,'company_name':company_name,'Exp_required':Exp_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "3f3539a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "2a95ff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71558c94",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location.\n",
    "You have to scrape the job-title, job-location, company_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "0e3f2c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\MohitLewis\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "21cd688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "9fb0ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "22c6a054",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "2829b1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "3bf35b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "e6967fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Science Specialist',\n",
       " 'Data Science Manager',\n",
       " 'Mongodb Database Administrator, Maria DB or Cassandra',\n",
       " 'Assistant Manager - Data Science',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Scientist: Artificial Intelligence',\n",
       " 'Data Scientist - Computer Vision',\n",
       " 'Senior Data Scientist']"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping job title from given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "2f7f3b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kolkata, Mumbai, Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru',\n",
       " 'Kolkata, Mumbai, Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Mumbai, Pune, Bangalore/Bengaluru',\n",
       " 'New Delhi, Pune, Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru',\n",
       " 'Mumbai, New Delhi, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Pune, Chennai, Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping job location from given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "f16826ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Accenture',\n",
       " 'Accenture',\n",
       " 'Mphasis',\n",
       " 'CitiusTech',\n",
       " 'ZS Associates',\n",
       " 'Tech Mahindra',\n",
       " 'Boston Consulting Group',\n",
       " 'IBM',\n",
       " 'Walmart',\n",
       " 'Wipro']"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scraping company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "ead902e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title[:10]), len(job_location[:10]), len(company_name[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "d5feffa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mongodb Database Administrator, Maria DB or Ca...</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>Mphasis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Mumbai, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>CitiusTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi, Pune, Gurgaon/Gurugram, Bangalore/B...</td>\n",
       "      <td>ZS Associates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Mumbai, New Delhi, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - Computer Vision</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0                            Data Science Specialist   \n",
       "1                               Data Science Manager   \n",
       "2  Mongodb Database Administrator, Maria DB or Ca...   \n",
       "3                   Assistant Manager - Data Science   \n",
       "4                                     Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6                              Senior Data Scientist   \n",
       "7            Data Scientist: Artificial Intelligence   \n",
       "8                   Data Scientist - Computer Vision   \n",
       "9                              Senior Data Scientist   \n",
       "\n",
       "                                        job_location             company_name  \n",
       "0  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...                Accenture  \n",
       "1  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...                Accenture  \n",
       "2  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...                  Mphasis  \n",
       "3                  Mumbai, Pune, Bangalore/Bengaluru               CitiusTech  \n",
       "4  New Delhi, Pune, Gurgaon/Gurugram, Bangalore/B...            ZS Associates  \n",
       "5  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...            Tech Mahindra  \n",
       "6    Mumbai, New Delhi, Chennai, Bangalore/Bengaluru  Boston Consulting Group  \n",
       "7                                Bangalore/Bengaluru                      IBM  \n",
       "8                                Bangalore/Bengaluru                  Walmart  \n",
       "9                 Pune, Chennai, Bangalore/Bengaluru                    Wipro  "
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating dataframe from above data\n",
    "df=pd.DataFrame({'job_title':job_title,'job_location':job_location,'company_name':company_name})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da90593d",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required. \n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "f00657da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first connect to the web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\MohitLewis\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "e9d57c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.naukri.com\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "659bdc9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"efcf9711e0df1d99baabb5f637e27a2d\", element=\"6f97dc2b-06fc-4e4c-95a0-c558e6dfb861\")>"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding element for job search bar\n",
    "search_job = driver.find_element(By.XPATH,\"//li[@class='nI-gNb-menuItems']\")\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "bcf3d729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write on search bar\n",
    "search_job=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "search_job.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "52350fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "af610f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying location and salary filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "affb858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_filter=driver.find_elements(By.XPATH,\"//div[@class='mt-8 chckBoxCont']//span\")\n",
    "\n",
    "\n",
    "for i in loc_filter :\n",
    "    if (i.text=='Delhi / NCR'):\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "cc5c8757",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_filter=driver.find_elements(By.XPATH,\"//div[@class='mt-8 chckBoxCont']//span\")\n",
    "for i in sal_filter:\n",
    "    if(i.text=='3-6 Lakhs'):\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "451b5753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so let's extract all the required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "f43d05ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "job=[]\n",
    "for i in job_title:\n",
    "    job.append(i.text)\n",
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "bfbf2a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title=driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "job=[]\n",
    "for i in job_title:\n",
    "    job.append(i.text)\n",
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "88c7b5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_name=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company=[]\n",
    "for i in comp_name:\n",
    "    company.append(i.text)\n",
    "    \n",
    "company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "756998e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_req=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "experience=[]\n",
    "for i in exp_req:\n",
    "    experience.append(i.text)\n",
    "experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "8dae3b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc=driver.find_elements(By.XPATH,\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "location=[]\n",
    "for i in loc:\n",
    "    location.append(i.text)\n",
    "    \n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "7184aad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating DataFrame for the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "4bb365fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JOB_TITLE</th>\n",
       "      <th>COMPANY_NAME</th>\n",
       "      <th>EXPERIENCE_REQUIRED</th>\n",
       "      <th>JOB_LOCATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [JOB_TITLE, COMPANY_NAME, EXPERIENCE_REQUIRED, JOB_LOCATION]\n",
       "Index: []"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame()\n",
    "df[\"JOB_TITLE\"]=job[:10]\n",
    "df[\"COMPANY_NAME\"]=company[:10]\n",
    "df[\"EXPERIENCE_REQUIRED\"]=experience[:10]\n",
    "df[\"JOB_LOCATION\"]=location[:10]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "95c85a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74b25d0",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "86fe8e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\MohitLewis\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "63432967",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.flipkart.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "15158b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_items=driver.find_element(By.XPATH,\"//input[@class='_3704LK']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "a89b6896",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_items.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "4463c546",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element(By.XPATH,\"//button[@class='L0Z3Pu']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "c17bfcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "cbe4a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating functions to scrape the similar attributes from different pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "fc222a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_brand_name(url):\n",
    "    Brand=[]\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        brand_name=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "        time.sleep(3)\n",
    "        \n",
    "        for i in brand_name:\n",
    "            \n",
    "            brand.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "            \n",
    "        return Brand\n",
    "    except StaleElementReferenceException as e:\n",
    "        print(\"exception raised\",e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "c9f4b77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_product_des(url):\n",
    "    P_desC=[]\n",
    "    driver.get(url)\n",
    "    P_desc=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "    for i in P_desc:\n",
    "        try:\n",
    "            product_des.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            product_des.append(\"--\")\n",
    "        \n",
    "    return product_des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "e1f05cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_price(url):\n",
    "    price=[]\n",
    "    driver.get(url)\n",
    "    price_el=driver.find_elements(By.XPATH,\"//div[@class='_3KxRU6 _2ssEMF']\")\n",
    "    \n",
    "    for i in price_el:\n",
    "        try:\n",
    "            price.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "            \n",
    "        except:\n",
    "            price.append(\"--\")\n",
    "        \n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "3a83e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_discount(url):\n",
    "    discount=[]\n",
    "    driver.get(url)\n",
    "    \n",
    "    discount_el=driver.find_elements(By.XPATH,\"//div[@class='_3Ay6Sb']/span\")\n",
    "        \n",
    "    for i in discount_el:\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            discount.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            discount.append(\"--\")\n",
    "        \n",
    "    return discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "68bc35a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "2847ced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]\n",
    "Price=[]\n",
    "P_desc=[]\n",
    "Discount=[]\n",
    "\n",
    "urls='https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page='\n",
    "for i in ['1','2','3']:\n",
    "\n",
    "   url= urls+i\n",
    "   time.sleep(5)\n",
    "   brand=scrape_brand_name(url)\n",
    "   Brand.extend(brand) \n",
    "   product=scrape_product_des(url)\n",
    "   product.extend(product)\n",
    "   discount=scrape_discount(url)\n",
    "   discount.extend(discount)\n",
    "   price=scrape_price(url)\n",
    "   price.extend(price) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "def44fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(P_desc),len(Discount),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "f5b60bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAND</th>\n",
       "      <th>PRODUCT_DESCRIPTION</th>\n",
       "      <th>DISCOUNT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [BRAND, PRODUCT_DESCRIPTION, DISCOUNT, PRICE]\n",
       "Index: []"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating DataFrame for the scraped Data\n",
    "df=pd.DataFrame()\n",
    "df[\"BRAND\"]=brand_list[:100]\n",
    "df[\"PRODUCT_DESCRIPTION\"]=product_list[:100]\n",
    "df[\"DISCOUNT\"]=discount_list[:100]\n",
    "df[\"PRICE\"]=price_list[:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50680bfe",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.flipkart.com/\n",
    "2. Enter “iphone 11” in “Search” field . \n",
    "3. Then click the search button.\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "ec74b2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\MohitLewis\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "a244117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "6054ef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "dd069f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_column=driver.find_element(By.XPATH,\"//input[@class='_3704LK']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "daaff404",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_column.send_keys('Iphone 11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "c71340a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element(By.XPATH,\"//button[@class='L0Z3Pu']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "1a24fd33",
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementClickInterceptedException",
     "evalue": "Message: element click intercepted: Element <button class=\"L0Z3Pu\" type=\"submit\">...</button> is not clickable at point (835, 28). Other element would receive the click: <div class=\"_2hriZF _2rbIyg\" tabindex=\"-1\">...</div>\n  (Session info: chrome=106.0.5249.62)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x0052DF13+2219795]\n\tOrdinal0 [0x004C2841+1779777]\n\tOrdinal0 [0x003D423D+803389]\n\tOrdinal0 [0x004099D4+1022420]\n\tOrdinal0 [0x004078C4+1013956]\n\tOrdinal0 [0x004054AB+1004715]\n\tOrdinal0 [0x00404117+999703]\n\tOrdinal0 [0x003F9B76+957302]\n\tOrdinal0 [0x0041E7FC+1107964]\n\tOrdinal0 [0x003F94B4+955572]\n\tOrdinal0 [0x0041EA14+1108500]\n\tOrdinal0 [0x0042F192+1175954]\n\tOrdinal0 [0x0041E616+1107478]\n\tOrdinal0 [0x003F7F89+950153]\n\tOrdinal0 [0x003F8F56+954198]\n\tGetHandleVerifier [0x00822CB2+3040210]\n\tGetHandleVerifier [0x00812BB4+2974420]\n\tGetHandleVerifier [0x005C6A0A+565546]\n\tGetHandleVerifier [0x005C5680+560544]\n\tOrdinal0 [0x004C9A5C+1808988]\n\tOrdinal0 [0x004CE3A8+1827752]\n\tOrdinal0 [0x004CE495+1827989]\n\tOrdinal0 [0x004D80A4+1867940]\n\tBaseThreadInitThunk [0x74B96359+25]\n\tRtlGetAppContainerNamedObjectPath [0x77187C24+228]\n\tRtlGetAppContainerNamedObjectPath [0x77187BF4+180]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m          Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MOHITL~1\\AppData\\Local\\Temp/ipykernel_9084/258053489.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msearch_btn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36mclick\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;34m\"\"\"Clicks the element.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLICK_ELEMENT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mWebElement\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    431\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m: Message: element click intercepted: Element <button class=\"L0Z3Pu\" type=\"submit\">...</button> is not clickable at point (835, 28). Other element would receive the click: <div class=\"_2hriZF _2rbIyg\" tabindex=\"-1\">...</div>\n  (Session info: chrome=106.0.5249.62)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x0052DF13+2219795]\n\tOrdinal0 [0x004C2841+1779777]\n\tOrdinal0 [0x003D423D+803389]\n\tOrdinal0 [0x004099D4+1022420]\n\tOrdinal0 [0x004078C4+1013956]\n\tOrdinal0 [0x004054AB+1004715]\n\tOrdinal0 [0x00404117+999703]\n\tOrdinal0 [0x003F9B76+957302]\n\tOrdinal0 [0x0041E7FC+1107964]\n\tOrdinal0 [0x003F94B4+955572]\n\tOrdinal0 [0x0041EA14+1108500]\n\tOrdinal0 [0x0042F192+1175954]\n\tOrdinal0 [0x0041E616+1107478]\n\tOrdinal0 [0x003F7F89+950153]\n\tOrdinal0 [0x003F8F56+954198]\n\tGetHandleVerifier [0x00822CB2+3040210]\n\tGetHandleVerifier [0x00812BB4+2974420]\n\tGetHandleVerifier [0x005C6A0A+565546]\n\tGetHandleVerifier [0x005C5680+560544]\n\tOrdinal0 [0x004C9A5C+1808988]\n\tOrdinal0 [0x004CE3A8+1827752]\n\tOrdinal0 [0x004CE495+1827989]\n\tOrdinal0 [0x004D80A4+1867940]\n\tBaseThreadInitThunk [0x74B96359+25]\n\tRtlGetAppContainerNamedObjectPath [0x77187C24+228]\n\tRtlGetAppContainerNamedObjectPath [0x77187BF4+180]\n"
     ]
    }
   ],
   "source": [
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36f5bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_rating():\n",
    "    rating=[]\n",
    "    driver.refresh()\n",
    "    rating_el=driver.find_elements(By.XPATH,\"//div[@class='_3LWZlK']\")\n",
    "    time.sleep(3)\n",
    "    for i in rating_el:\n",
    "        try:\n",
    "            rating.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            rating.append(\"--\")\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7204d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_review_summary():\n",
    "    review_sum=[]\n",
    "    driver.refresh()\n",
    "    rev_sum=driver.find_elements(By.XPATH,\"//p[@class='_2-N8zT']\")\n",
    "    time.sleep(3)\n",
    "    for i in rev_sum:\n",
    "        try:\n",
    "            review_sum.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            review_sum.append(\"--\")\n",
    "    return review_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066f16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_full_review():\n",
    "    full_review=[]\n",
    "    driver.refresh()\n",
    "    rev_el=driver.find_elements(By.XPATH,\"//div[@class='t-ZTKy']/div\")\n",
    "    time.sleep(3)\n",
    "    for i in rev_el:\n",
    "        try:\n",
    "            full_review.append(i.text.replace(\"\\n\",\"  New Line: \"))\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            full_review.append(\"--\")\n",
    "    return full_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0ad071",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=[]\n",
    "review_sum=[]\n",
    "full_review=[]\n",
    "length=len(rating)\n",
    "while(length<=100):\n",
    "    driver.refresh()\n",
    "    rating.extend(scrape_rating())\n",
    "    review_sum.extend(scrape_review_summary())\n",
    "    full_review.extend(scrape_full_review())\n",
    "    time.sleep(5)\n",
    "    length=len(rating)\n",
    "    next_btn=driver.find_element(By.XPATH,\"//a[@class='_1LKTO3']/span\")\n",
    "    next_btn.click()\n",
    "    \n",
    "len(review_sum)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe7a875",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if the data was scraped properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57921183",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_list=[len(full_review),len(rating),len(review_sum)]\n",
    "length_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a79962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f7b744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a DataFrame for the scraped data\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df[\"INDEX\"]=range(1,101)\n",
    "df[\"RATING\"]=rating[:100]\n",
    "df[\"REVIEW_SUMMARY\"]=review_sum[:100]\n",
    "df[\"FULL_REVIEW\"]=full_review[:100]\n",
    "df.set_index(\"INDEX\",inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ff4187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2766539f",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the \n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86acbc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\MohitLewis\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b4c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05eab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_column=driver.find_element(By.XPATH,\"//input[@class='_3704LK']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ea27ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_column.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce7ecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element(By.XPATH,\"//button[@class='L0Z3Pu']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db9cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beee4c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_brand():\n",
    "    brand=[]\n",
    "    brand_el=driver.find_element(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    time.sleep(3)\n",
    "    for i in brand_el:\n",
    "        try:\n",
    "            brand.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            brand.append(\"--\")\n",
    "    return brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ddb17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_product_des():\n",
    "    product_des=[]\n",
    "    des_el=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "    print(len(des_el))\n",
    "    time.sleep(3)\n",
    "    for i in des_el:\n",
    "        try:\n",
    "            product_des.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            product_des.append(\"--\")\n",
    "    return product_des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d51f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_price():\n",
    "    price=[]\n",
    "    price_el=driver.find_elements(By.XPATH,\"//div[@class='_3I9_wc']\")\n",
    "    time.sleep(3)\n",
    "    for i in price_el:\n",
    "        try:\n",
    "            price.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            price.append(\"--\")\n",
    "            \n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d093318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_discount():\n",
    "    discount=[]\n",
    "    discount_el=driver.find_elements(By.XPATH,\"//div[@class='_3Ay6Sb']/span\")\n",
    "    time.sleep(3)\n",
    "    for i in discount_el:\n",
    "        try:\n",
    "            discount.append(i.text)\n",
    "            driver.execute_script(\"window.scrollBy(0,document.body.scrollHeight0)\")\n",
    "        except:\n",
    "            discount.append(\"--\")\n",
    "            \n",
    "    return discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7060b5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "product_des=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "length=len(brand)\n",
    "while(length<=100):\n",
    "    driver.refresh()\n",
    "    brand.extend(scrape_brand())\n",
    "    product_des.extend(scrape_product_des())\n",
    "    price.extend(scrape_price())\n",
    "    discount.extend(scrape_discount())\n",
    "    time.sleep(3)\n",
    "    next_btn=driver.find_element(By.XPATH,\"//a[@class='_1LKTO3']/span\")\n",
    "    next_btn.click()\n",
    "    length=len(brand)\n",
    "len(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47717f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b72926",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_name=[]\n",
    "Price=[]\n",
    "P_desc=[]\n",
    "Discount=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c84fa65",
   "metadata": {},
   "source": [
    "# Q7: Go to the link - https://www.myntra.com/shoes\n",
    "Set second Price filter and Color filter to “Black”, as shown in the below image.\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe \n",
    "description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38414d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\MohitLewis\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a870bfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.myntra.com/shoes\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0aa8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fac8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appplying the price filter\n",
    "Price_filter=driver.find_elements(By.XPATH,\"//label[@class='common-customerCheckbox vertical-filters-label']\")\n",
    "for i in Price_filter:\n",
    "    if i.text==\"Rs. 6649 to Rs. 13099\":\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfdd057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the black colur filter\n",
    "Color_filter=driver.find_elements(By.XPATH,\"//li[@class='colour-listItem']\")\n",
    "for i in Color_filter:\n",
    "    if i.text==\"Black\":\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cb18a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    b_name=driver.find_elements(By.XPATH,\"//h1[@class='pdp-title']\")\n",
    "    p_desc=driver.find_elements(By.XPATH,\"//h1[@class='name']\")\n",
    "    price =driver.find_elements(By.XPATH,\"//div[@class='product-price']\")\n",
    " \n",
    "    for j  in b_name:\n",
    "        B_name.append(j.text)\n",
    "    B_name[:100]    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for k in p_desc:\n",
    "        P_desc.append(k.text)\n",
    "    P_desc[:100] \n",
    "    \n",
    "    \n",
    "    for l in price:\n",
    "        Price.append(l.text)\n",
    "    Price[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf2ef85",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "description=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56ae1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(B_name[:100])),print(len(Price[:100])),print(len(P_desc[:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac275ab",
   "metadata": {},
   "source": [
    "# Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” \n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e09fe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:\\Users\\MohitLewis\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccae0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "url= \"https://www.amazon.in/\"\n",
    "driver.get(\" https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2d6243",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fc2590",
   "metadata": {},
   "outputs": [],
   "source": [
    "Product= driver.find_element(By.ID,\"twotabsearchtextbox\")\n",
    "Product.send_keys(\"Laptop\")              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dcd328",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.ID,\"nav-search-submit-button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea957e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_el=driver.find_elements(By.XPATH,\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']\")\n",
    "title=[]\n",
    "for i in title_el[:10]:\n",
    "    title.append(i.text)\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625e416a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title_laptop=driver.find_elements(By.XPATH,'//h2[@class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-2\"]')\n",
    "for i in Title_laptop[:10]:\n",
    "    title=i.text\n",
    "    Title_laptop.append(title)\n",
    "Title_laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fe2ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Price_laptop=driver.find_elements(By.XPATH,\"//span[@class='a-price-whole']\")\n",
    "for i in Price_laptop[:10]:\n",
    "    price=i.text\n",
    "    Price_laptop.append(price) \n",
    "Price_laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a52ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url2=driver.find_elements(By.XPATH,\"//a[@class='a-link-normal a-text-normal']\")\n",
    "\n",
    "rating_url=[]\n",
    "for i in url2[0:10]:\n",
    "    rating_url.append(i.get_attribute('href'))\n",
    "rating_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c985b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "rating=[]\n",
    "for i in rating_url[:10]:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        \n",
    "        ratings = driver.find_element(By.XPATH,\".//span[@class='a-icon-alt']/..\")\n",
    "        ratings = ratings.get_attribute('innerHTML').split(\">\")[1].split(\" \")[0]\n",
    "        rating.append(ratings)\n",
    "    except:\n",
    "        \n",
    "        \n",
    "        rating.append(\"00\")\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cbbf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Title_laptop),len(Rating_laptop),len(Price_laptop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85918f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating DataFrame for the scraped data\n",
    "laptop_df=pd.DataFrame()\n",
    "laptop_df['INDEX']=range(1,11)\n",
    "laptop_df['TITLE']=title[:10]\n",
    "laptop_df['RATING']=rating[:10]\n",
    "laptop_df['PRICE']=price[:10]\n",
    "laptop_df.set_index('INDEX',inplace=True)\n",
    "laptop_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
